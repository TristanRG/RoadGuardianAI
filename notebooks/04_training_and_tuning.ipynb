{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a1a4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RND = 42\n",
    "np.random.seed(RND)\n",
    "\n",
    "ROOT = Path(\"..\")\n",
    "DATA_DIR = ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR = ROOT / \"models\"\n",
    "FIG_DIR = ROOT / \"figures\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PARQUET = DATA_DIR / \"train_with_label_1h.parquet\"\n",
    "TEST_PARQUET  = DATA_DIR / \"test_with_label_1h.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a97642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 1653203 Test rows: 318852\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(TRAIN_PARQUET)\n",
    "test  = pd.read_parquet(TEST_PARQUET)\n",
    "\n",
    "train = train.sort_values(\"ts\").reset_index(drop=True)\n",
    "test  = test.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "print(\"Train rows:\", len(train), \"Test rows:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edc36c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_te added. Global mean: 0.06642136507131913\n"
     ]
    }
   ],
   "source": [
    "global_mean = train['label_1h'].mean()\n",
    "\n",
    "grp = train.groupby('segment_id')['label_1h']\n",
    "train['seg_count_so_far'] = grp.cumcount()\n",
    "train['seg_sum_so_far']   = grp.cumsum() - train['label_1h']\n",
    "train['seg_mean_so_far']  = train['seg_sum_so_far'] / train['seg_count_so_far'].replace(0, np.nan)\n",
    "\n",
    "k = 10.0\n",
    "train['seg_te_smoothed'] = (train['seg_mean_so_far'] * train['seg_count_so_far'] + global_mean * k) / (train['seg_count_so_far'] + k)\n",
    "train['seg_te_smoothed'] = train['seg_te_smoothed'].fillna(global_mean)\n",
    "\n",
    "agg = train.groupby('segment_id').agg(n=('label_1h','count'), s=('label_1h','sum'))\n",
    "agg['mean'] = agg['s'] / agg['n']\n",
    "agg['te_smoothed'] = (agg['mean'] * agg['n'] + global_mean * k) / (agg['n'] + k)\n",
    "seg_te_map = agg['te_smoothed'].to_dict()\n",
    "\n",
    "train['seg_te'] = train['seg_te_smoothed']\n",
    "test['seg_te']  = test['segment_id'].map(seg_te_map).fillna(global_mean)\n",
    "\n",
    "train = train.drop(columns=['seg_count_so_far','seg_sum_so_far','seg_mean_so_far','seg_te_smoothed'])\n",
    "print(\"seg_te added. Global mean:\", global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd036db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cyclical(df):\n",
    "    df['hour'] = pd.to_datetime(df['ts']).dt.hour\n",
    "    df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "    df['weekday'] = pd.to_datetime(df['ts']).dt.weekday\n",
    "    df['weekday_sin'] = np.sin(2*np.pi*df['weekday']/7)\n",
    "    df['weekday_cos'] = np.cos(2*np.pi*df['weekday']/7)\n",
    "    return df\n",
    "\n",
    "train = add_cyclical(train)\n",
    "test  = add_cyclical(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8788152",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_CLUSTER = True\n",
    "K_CLUSTERS = 200\n",
    "\n",
    "if DO_CLUSTER:\n",
    "    coords = train[['LATITUDE','LONGITUDE']].dropna()\n",
    "    kmeans = MiniBatchKMeans(n_clusters=K_CLUSTERS, random_state=RND, batch_size=10000)\n",
    "    kmeans.fit(coords)\n",
    "    train['cluster'] = kmeans.predict(train[['LATITUDE','LONGITUDE']].fillna(0))\n",
    "    test['cluster']  = kmeans.predict(test[['LATITUDE','LONGITUDE']].fillna(0))\n",
    "\n",
    "    cluster_agg = train.groupby('cluster')['label_1h'].agg(['count','mean'])\n",
    "    cluster_global = train['label_1h'].mean()\n",
    "    cluster_agg['te'] = (cluster_agg['mean']*cluster_agg['count'] + cluster_global*10.0) / (cluster_agg['count'] + 10.0)\n",
    "    cluster_te_map = cluster_agg['te'].to_dict()\n",
    "    train['cluster_te'] = train['cluster'].map(cluster_te_map).fillna(cluster_global)\n",
    "    test['cluster_te']  = test['cluster'].map(cluster_te_map).fillna(cluster_global)\n",
    "else:\n",
    "    train['cluster_te'] = np.nan\n",
    "    test['cluster_te']  = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a15076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos', 'LATITUDE', 'LONGITUDE', 'sev_1h', 'sev_6h', 'sev_24h', 'tot_1h', 'tot_6h', 'tot_24h', 'seg_te', 'cluster_te']\n",
      "X_train shape: (1653203, 14) X_test shape: (318852, 14)\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"label_1h\"\n",
    "DROP_COLS = [\"ts\",\"date\",\"segment_id\",\"BOROUGH\",\"ZIP CODE\",\"ON STREET NAME\",\"CROSS STREET NAME\",\"COLLISION_ID\",\"window_start\"]\n",
    "\n",
    "# Prefer numeric columns + engineered ones\n",
    "candidate_feats = [\n",
    "    'hour_sin','hour_cos','weekday_sin','weekday_cos',\n",
    "    'LATITUDE','LONGITUDE',\n",
    "    'sev_1h','sev_6h','sev_24h','tot_1h','tot_6h','tot_24h',\n",
    "    'seg_te','cluster_te'\n",
    "]\n",
    "\n",
    "# Filter only those present in the data\n",
    "features = [f for f in candidate_feats if f in train.columns]\n",
    "print(\"Using features:\", features)\n",
    "\n",
    "X_train = train[features].copy()\n",
    "y_train = train[TARGET].astype(int).copy()\n",
    "X_test  = test[features].copy()\n",
    "y_test  = test[TARGET].astype(int).copy()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09908f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.967224\n",
      "Fold 1 AUC: 0.9672\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.96739\n",
      "Fold 2 AUC: 0.9674\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.966895\n",
      "Fold 3 AUC: 0.9669\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.969157\n",
      "Fold 4 AUC: 0.9692\n",
      "Mean CV AUC: 0.9667615921553058\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"boosting_type\":\"gbdt\",\n",
    "    \"seed\":RND,\n",
    "    \"verbosity\":-1,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"max_depth\": -1\n",
    "}\n",
    "\n",
    "aucs = []\n",
    "fold = 0\n",
    "for tr_idx, val_idx in tscv.split(X_train):\n",
    "    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    dtr = lgb.Dataset(X_tr, label=y_tr)\n",
    "    dval = lgb.Dataset(X_val, label=y_val, reference=dtr)\n",
    "    bst = lgb.train(params, dtr, num_boost_round=500, valid_sets=[dval], callbacks=[lgb.callback.early_stopping(50), lgb.callback.log_evaluation(period=0)])\n",
    "    yv = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
    "    auc_fold = roc_auc_score(y_val, yv)\n",
    "    print(f\"Fold {fold} AUC: {auc_fold:.4f}\")\n",
    "    aucs.append(auc_fold)\n",
    "    fold += 1\n",
    "\n",
    "print(\"Mean CV AUC:\", np.mean(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be268cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.971194\tvalid_1's auc: 0.962197\n",
      "[100]\ttraining's auc: 0.97263\tvalid_1's auc: 0.963366\n",
      "[150]\ttraining's auc: 0.973646\tvalid_1's auc: 0.963353\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's auc: 0.973309\tvalid_1's auc: 0.963454\n",
      "Best iteration: 133\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dtest  = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
    "\n",
    "final_params = {**params}\n",
    "bst_final = lgb.train(final_params, dtrain, num_boost_round=2000, valid_sets=[dtrain,dtest],\n",
    "                      callbacks=[lgb.callback.early_stopping(50), lgb.callback.log_evaluation(period=50)])\n",
    "\n",
    "best_iter = bst_final.best_iteration if getattr(bst_final, \"best_iteration\", None) else None\n",
    "print(\"Best iteration:\", best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bca7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9513, F1: 0.4381, AUC: 0.9635\n",
      "Prevalence (test): 0.048367267572416044\n",
      "Model precision@5%: 0.4809\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = bst_final.predict(X_test, num_iteration=best_iter)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1  = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "prevalence = y_test.mean()\n",
    "k = 0.05\n",
    "n_top = max(1, int(k * len(y_pred_prob)))\n",
    "top_idx = np.argsort(y_pred_prob)[-n_top:]\n",
    "model_prec_at_k = y_test.iloc[top_idx].mean()\n",
    "print(\"Prevalence (test):\", prevalence)\n",
    "print(f\"Model precision@{int(k*100)}%: {model_prec_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc8e0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ..\\models\\lgb_baseline_model.txt and ..\\models\\lgb_baseline_model.joblib\n",
      "Saved encoders/maps to: ..\\models\\label_encoders.joblib\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH_TXT = OUT_DIR / \"lgb_baseline_model.txt\"\n",
    "MODEL_PATH_JOBLIB = OUT_DIR / \"lgb_baseline_model.joblib\"\n",
    "ENC_PATH = OUT_DIR / \"label_encoders.joblib\"\n",
    "\n",
    "bst_final.save_model(str(MODEL_PATH_TXT))\n",
    "joblib.dump(bst_final, str(MODEL_PATH_JOBLIB))\n",
    "\n",
    "to_save = {'seg_te_map': seg_te_map}\n",
    "if 'cluster_te_map' in globals():\n",
    "    to_save['cluster_te_map'] = cluster_te_map\n",
    "joblib.dump(to_save, str(ENC_PATH))\n",
    "\n",
    "print(\"Saved model to:\", MODEL_PATH_TXT, \"and\", MODEL_PATH_JOBLIB)\n",
    "print(\"Saved encoders/maps to:\", ENC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73bced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP summary to: ..\\figures\\shap_summary_beeswarm.png\n"
     ]
    }
   ],
   "source": [
    "X_sample = X_test.sample(n=min(2000, len(X_test)), random_state=RND)\n",
    "\n",
    "explainer = shap.TreeExplainer(bst_final)\n",
    "svals = explainer.shap_values(X_sample)\n",
    "shap_for_pos = svals[1] if isinstance(svals, (list,tuple)) else svals\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "try:\n",
    "    shap.summary_plot(shap_for_pos, X_sample, show=False)\n",
    "except Exception:\n",
    "    shap.plots.beeswarm(shap.Explanation(values=shap_for_pos, data=X_sample, feature_names=list(X_sample.columns)))\n",
    "out = FIG_DIR / \"shap_summary_beeswarm.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved SHAP summary to:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43bb1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SHAP dependence plot to: ..\\figures\\shap_dependence_seg_te.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat = 'seg_te'\n",
    "if feat in X_test.columns:\n",
    "    X_dep = X_test.sample(n=min(5000, len(X_test)), random_state=RND)\n",
    "    svals_dep = explainer.shap_values(X_dep)\n",
    "    shap_vals_dep = svals_dep[1] if isinstance(svals_dep, (list,tuple)) else svals_dep\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    try:\n",
    "        shap.dependence_plot(feat, shap_vals_dep, X_dep, show=False)\n",
    "    except Exception:\n",
    "        shap.plots.scatter(shap.Explanation(values=shap_vals_dep, data=X_dep, feature_names=list(X_dep.columns)), x=feat)\n",
    "    out2 = FIG_DIR / \"shap_dependence_seg_te.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out2, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"Saved SHAP dependence plot to:\", out2)\n",
    "else:\n",
    "    print(feat, \"not in features, skipping dependence plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roadguardianai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
